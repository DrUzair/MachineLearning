{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Gaussian Naive Bayes - Classification of Iris\n",
        "**Uzair Ahmad**"
      ],
      "metadata": {
        "id": "zOU92mxvcXp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a simple example using the famous Iris dataset from the `scikit-learn` library. This dataset comprises 3 classes of 50 instances each, where each class refers to a type of iris plant.\n"
      ],
      "metadata": {
        "id": "kNOwZDA0baf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Loading the Dataset\n",
        "\n",
        "First, we'll load the Iris dataset from `scikit-learn`.\n"
      ],
      "metadata": {
        "id": "I_1DYqvcbaS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n"
      ],
      "metadata": {
        "id": "TKt_Ld7tbhyl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Splitting the Dataset\n",
        "\n",
        "Before training our model, we'll split the dataset into a training set and a test set. This allows us to evaluate the model's performance on unseen data.\n"
      ],
      "metadata": {
        "id": "K29h_Y5pblBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "Ft0VFmrCbmOB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 3: Training the Gaussian Naive Bayes Classifier\n",
        "\n",
        "Now, we'll train the Gaussian Naive Bayes classifier using the training data.\n",
        "\n"
      ],
      "metadata": {
        "id": "mKEsZe5gbsdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "29riLJr6bvyA",
        "outputId": "85678188-b2af-42b5-c2c3-da3463289ccf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the parameters\n",
        "print(\"Class Priors (class_prior_):\")\n",
        "print(gnb.class_prior_)\n",
        "\n",
        "print(\"\\nClass Counts (class_count_):\")\n",
        "print(gnb.class_count_)\n",
        "\n",
        "print(\"\\nMeans of each feature per class (theta_):\")\n",
        "print(gnb.theta_)\n",
        "\n",
        "print(\"\\nVariances of each feature per class (sigma_):\")\n",
        "print(gnb.var_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enbk2rZn9rl_",
        "outputId": "93092667-2165-45d8-fae4-dba39ab2ffae"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Priors (class_prior_):\n",
            "[0.2952381  0.35238095 0.35238095]\n",
            "\n",
            "Class Counts (class_count_):\n",
            "[31. 37. 37.]\n",
            "\n",
            "Means of each feature per class (theta_):\n",
            "[[4.96451613 3.37741935 1.46451613 0.2483871 ]\n",
            " [5.86216216 2.72432432 4.21081081 1.3027027 ]\n",
            " [6.55945946 2.98648649 5.54594595 2.00540541]]\n",
            "\n",
            "Variances of each feature per class (sigma_):\n",
            "[[0.1119667  0.13658689 0.03325703 0.01152966]\n",
            " [0.27532506 0.08724617 0.23934259 0.04134405]\n",
            " [0.42241052 0.09630387 0.28842951 0.08591673]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 4: Making Predictions\n",
        "\n",
        "With our trained model, we can now make predictions on the test set.\n",
        "\n"
      ],
      "metadata": {
        "id": "tH5OSHAPbzBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = gnb.predict(X_test)\n"
      ],
      "metadata": {
        "id": "eE3u4zdycQT0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Evaluating the Model\n",
        "\n",
        "To evaluate the performance of our classifier, we can use metrics such as accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "wtPx8x5tb2tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiCh4CV4cBZ0",
        "outputId": "0bcc9b07-fd2a-4c54-e62d-cb16dcc0fa96"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the code should give you the accuracy of the Gaussian Naive Bayes classifier on the test set of the Iris dataset. Typically, the GNB classifier does quite well on this dataset.\n",
        "\n",
        "Remember, the actual accuracy may vary slightly based on the random split of data in the `train_test_split` function."
      ],
      "metadata": {
        "id": "JtJi35BEb9jf"
      }
    }
  ]
}